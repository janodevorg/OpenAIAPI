{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"CreateChatCompletionRequest"}],"languages":["swift"],"platforms":["macOS"]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/openaiapi\/createchatcompletionrequest"],"traits":[{"interfaceLanguage":"swift"}]}],"relationshipsSections":[{"identifiers":["doc:\/\/OpenAIAPI\/Se","doc:\/\/OpenAIAPI\/SE"],"kind":"relationships","title":"Conforms To","type":"conformsTo"}],"identifier":{"url":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest","interfaceLanguage":"swift"},"topicSections":[{"title":"Initializers","identifiers":["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/init(from:)","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/init(model:messages:temperature:topP:n:isStream:stop:maxTokens:presencePenalty:frequencyPenalty:logitBias:user:)"]},{"title":"Instance Properties","identifiers":["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/frequencyPenalty","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/isStream","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/logitBias","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/maxTokens","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/messages","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/model","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/n","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/presencePenalty","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/stop-swift.property","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/temperature","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/topP","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/user"]},{"title":"Instance Methods","identifiers":["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/encode(to:)"]},{"title":"Enumerations","identifiers":["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/Stop-swift.enum"]}],"kind":"symbol","metadata":{"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"CreateChatCompletionRequest"}],"title":"CreateChatCompletionRequest","roleHeading":"Structure","role":"symbol","symbolKind":"struct","externalID":"s:9OpenAIAPI27CreateChatCompletionRequestV","modules":[{"name":"OpenAIAPI"}],"navigatorTitle":[{"kind":"identifier","text":"CreateChatCompletionRequest"}]},"hierarchy":{"paths":[["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI"]]},"references":{"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/n":{"role":"symbol","title":"n","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"n"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"How many chat completion choices to generate for each input message."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/n","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/n"},"doc://OpenAIAPI/SE":{"type":"unresolvable","title":"Swift.Encodable","identifier":"doc:\/\/OpenAIAPI\/SE"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/maxTokens":{"role":"symbol","title":"maxTokens","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens)."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/maxTokens","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/maxtokens"},"/docs/guides/safety-best-practices/end-user-ids":{"title":"Learn more","titleInlineContent":[{"type":"text","text":"Learn more"}],"type":"link","identifier":"\/docs\/guides\/safety-best-practices\/end-user-ids","url":"\/docs\/guides\/safety-best-practices\/end-user-ids"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/messages":{"role":"symbol","title":"messages","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"messages"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","text":"ChatCompletionRequestMessage","preciseIdentifier":"s:9OpenAIAPI28ChatCompletionRequestMessageV"},{"kind":"text","text":"]"}],"abstract":[{"type":"text","text":"The messages to generate chat completions for, in the "},{"type":"reference","isActive":true,"identifier":"\/docs\/guides\/chat\/introduction"},{"type":"text","text":"."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/messages","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/messages"},"doc://OpenAIAPI/documentation/OpenAIAPI":{"role":"collection","title":"OpenAIAPI","abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/isStream":{"role":"symbol","title":"isStream","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"isStream"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"}],"abstract":[{"type":"text","text":"If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/API\/Server-sent_events\/Using_server-sent_events#Event_stream_format"},{"type":"text","text":" as they become available, with the stream terminated by a "},{"type":"codeVoice","code":"data: [DONE]"},{"type":"text","text":" message."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/isStream","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/isstream"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/init(from:)":{"role":"symbol","title":"init(from:)","fragments":[{"kind":"identifier","text":"init"},{"kind":"text","text":"("},{"kind":"externalParam","text":"from"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Decoder","preciseIdentifier":"s:s7DecoderP"},{"kind":"text","text":") "},{"kind":"keyword","text":"throws"}],"abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/init(from:)","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/init(from:)"},"https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format":{"title":"server-sent events","titleInlineContent":[{"type":"text","text":"server-sent events"}],"type":"link","identifier":"https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/API\/Server-sent_events\/Using_server-sent_events#Event_stream_format","url":"https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/API\/Server-sent_events\/Using_server-sent_events#Event_stream_format"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/temperature":{"role":"symbol","title":"temperature","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/temperature","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/temperature"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/logitBias":{"role":"symbol","title":"logitBias","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"logitBias"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":" : "},{"kind":"typeIdentifier","text":"AnyJSON","preciseIdentifier":"s:9OpenAIAPI7AnyJSONO"},{"kind":"text","text":"]?"}],"abstract":[{"type":"text","text":"Modify the likelihood of specified tokens appearing in the completion."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/logitBias","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/logitbias"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/Stop-swift.enum":{"role":"symbol","title":"CreateChatCompletionRequest.Stop","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"Stop"}],"abstract":[{"type":"text","text":"Up to 4 sequences where the API will stop generating further tokens."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/Stop-swift.enum","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"Stop"}],"url":"\/documentation\/openaiapi\/createchatcompletionrequest\/stop-swift.enum"},"/docs/guides/chat/introduction":{"title":"chat format","titleInlineContent":[{"type":"text","text":"chat format"}],"type":"link","identifier":"\/docs\/guides\/chat\/introduction","url":"\/docs\/guides\/chat\/introduction"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/frequencyPenalty":{"role":"symbol","title":"frequencyPenalty","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"frequencyPenalty"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/frequencyPenalty","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/frequencypenalty"},"doc://OpenAIAPI/Se":{"type":"unresolvable","title":"Swift.Decodable","identifier":"doc:\/\/OpenAIAPI\/Se"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest":{"role":"symbol","title":"CreateChatCompletionRequest","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"CreateChatCompletionRequest"}],"abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"CreateChatCompletionRequest"}],"url":"\/documentation\/openaiapi\/createchatcompletionrequest"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/presencePenalty":{"role":"symbol","title":"presencePenalty","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"presencePenalty"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/presencePenalty","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/presencepenalty"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/topP":{"role":"symbol","title":"topP","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"topP"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/topP","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/topp"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/stop-swift.property":{"role":"symbol","title":"stop","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"stop"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"CreateChatCompletionRequest","preciseIdentifier":"s:9OpenAIAPI27CreateChatCompletionRequestV"},{"kind":"text","text":"."},{"kind":"typeIdentifier","text":"Stop","preciseIdentifier":"s:9OpenAIAPI27CreateChatCompletionRequestV4StopO"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"Up to 4 sequences where the API will stop generating further tokens."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/stop-swift.property","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/stop-swift.property"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/model":{"role":"symbol","title":"model","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"model"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"}],"abstract":[{"type":"text","text":"ID of the model to use. Currently, only "},{"type":"codeVoice","code":"gpt-3.5-turbo"},{"type":"text","text":" and "},{"type":"codeVoice","code":"gpt-3.5-turbo-0301"},{"type":"text","text":" are supported."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/model","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/model"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/encode(to:)":{"role":"symbol","title":"encode(to:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"encode"},{"kind":"text","text":"("},{"kind":"externalParam","text":"to"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Encoder","preciseIdentifier":"s:s7EncoderP"},{"kind":"text","text":") "},{"kind":"keyword","text":"throws"}],"abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/encode(to:)","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/encode(to:)"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/init(model:messages:temperature:topP:n:isStream:stop:maxTokens:presencePenalty:frequencyPenalty:logitBias:user:)":{"role":"symbol","title":"init(model:messages:temperature:topP:n:isStream:stop:maxTokens:presencePenalty:frequencyPenalty:logitBias:user:)","fragments":[{"kind":"identifier","text":"init"},{"kind":"text","text":"("},{"kind":"externalParam","text":"model"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":", "},{"kind":"externalParam","text":"messages"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","text":"ChatCompletionRequestMessage","preciseIdentifier":"s:9OpenAIAPI28ChatCompletionRequestMessageV"},{"kind":"text","text":"], "},{"kind":"externalParam","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"topP"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"n"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"isStream"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"stop"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"CreateChatCompletionRequest","preciseIdentifier":"s:9OpenAIAPI27CreateChatCompletionRequestV"},{"kind":"text","text":"."},{"kind":"typeIdentifier","text":"Stop","preciseIdentifier":"s:9OpenAIAPI27CreateChatCompletionRequestV4StopO"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"presencePenalty"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"frequencyPenalty"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"logitBias"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":" : "},{"kind":"typeIdentifier","text":"AnyJSON","preciseIdentifier":"s:9OpenAIAPI7AnyJSONO"},{"kind":"text","text":"]?, "},{"kind":"externalParam","text":"user"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":"?)"}],"abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/init(model:messages:temperature:topP:n:isStream:stop:maxTokens:presencePenalty:frequencyPenalty:logitBias:user:)","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/init(model:messages:temperature:topp:n:isstream:stop:maxtokens:presencepenalty:frequencypenalty:logitbias:user:)"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/user":{"role":"symbol","title":"user","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"user"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. "},{"type":"reference","isActive":true,"identifier":"\/docs\/guides\/safety-best-practices\/end-user-ids"},{"type":"text","text":"."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/user","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/user"}}}
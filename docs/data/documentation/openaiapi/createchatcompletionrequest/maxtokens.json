{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"languages":["swift"],"platforms":["macOS"]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/openaiapi\/createchatcompletionrequest\/maxtokens"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/maxTokens","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens)."}],"kind":"symbol","metadata":{"fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"title":"maxTokens","roleHeading":"Instance Property","role":"symbol","symbolKind":"property","externalID":"s:9OpenAIAPI27CreateChatCompletionRequestV9maxTokensSiSgvp","modules":[{"name":"OpenAIAPI"}]},"hierarchy":{"paths":[["doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI","doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest"]]},"references":{"doc://OpenAIAPI/documentation/OpenAIAPI":{"role":"collection","title":"OpenAIAPI","abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest/maxTokens":{"role":"symbol","title":"maxTokens","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Int","preciseIdentifier":"s:Si"},{"kind":"text","text":"?"}],"abstract":[{"type":"text","text":"The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens)."}],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest\/maxTokens","kind":"symbol","type":"topic","url":"\/documentation\/openaiapi\/createchatcompletionrequest\/maxtokens"},"doc://OpenAIAPI/documentation/OpenAIAPI/CreateChatCompletionRequest":{"role":"symbol","title":"CreateChatCompletionRequest","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"CreateChatCompletionRequest"}],"abstract":[],"identifier":"doc:\/\/OpenAIAPI\/documentation\/OpenAIAPI\/CreateChatCompletionRequest","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"CreateChatCompletionRequest"}],"url":"\/documentation\/openaiapi\/createchatcompletionrequest"}}}
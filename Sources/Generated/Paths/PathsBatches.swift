// Generated by Create API
// https://github.com/CreateAPI/CreateAPI

import Foundation
import Get
import HTTPHeaders
import URLQueryEncoder

extension Paths {
    public static var batches: Batches {
        Batches(path: "/batches")
    }

    public struct Batches {
        /// Path: `/batches`
        public let path: String

        /// List your organization's batches.
        public func get(after: String? = nil, limit: Int? = nil) -> Request<OpenAIAPI.ListBatchesResponse> {
            Request(path: path, method: "GET", query: makeGetQuery(after, limit), id: "listBatches")
        }

        private func makeGetQuery(_ after: String?, _ limit: Int?) -> [(String, String?)] {
            let encoder = URLQueryEncoder()
            encoder.encode(after, forKey: "after")
            encoder.encode(limit, forKey: "limit")
            return encoder.items
        }

        /// Creates and executes a batch from an uploaded file of requests
        public func post(_ body: PostRequest) -> Request<OpenAIAPI.Batch> {
            Request(path: path, method: "POST", body: body, id: "createBatch")
        }

        public struct PostRequest: Encodable {
            /// The ID of an uploaded file that contains requests for the new batch.
            /// 
            /// See [upload file](/docs/api-reference/files/create) for how to upload a file.
            /// 
            /// Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.
            public var inputFileID: String
            /// The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
            public var endpoint: Endpoint
            /// The time frame within which the batch should be processed. Currently only `24h` is supported.
            public var completionWindow: CompletionWindow
            /// Optional custom metadata for the batch.
            public var metadata: [String: String]?

            /// The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
            public enum Endpoint: String, Codable, CaseIterable {
                case v1ChatCompletions = "/v1/chat/completions"
                case v1Embeddings = "/v1/embeddings"
                case v1Completions = "/v1/completions"
            }

            /// The time frame within which the batch should be processed. Currently only `24h` is supported.
            public enum CompletionWindow: String, Codable, CaseIterable {
                case _24h = "24h"
            }

            public init(inputFileID: String, endpoint: Endpoint, completionWindow: CompletionWindow, metadata: [String: String]? = nil) {
                self.inputFileID = inputFileID
                self.endpoint = endpoint
                self.completionWindow = completionWindow
                self.metadata = metadata
            }

            public func encode(to encoder: Encoder) throws {
                var values = encoder.container(keyedBy: StringCodingKey.self)
                try values.encode(inputFileID, forKey: "input_file_id")
                try values.encode(endpoint, forKey: "endpoint")
                try values.encode(completionWindow, forKey: "completion_window")
                try values.encodeIfPresent(metadata, forKey: "metadata")
            }
        }
    }
}

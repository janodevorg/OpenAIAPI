// Generated by Create API
// https://github.com/CreateAPI/CreateAPI

import Foundation

public struct CreateChatCompletionRequest: Codable {
    /// ID of the model to use. Currently, only `gpt-3.5-turbo` and `gpt-3.5-turbo-0301` are supported.
    public var model: String
    /// The messages to generate chat completions for, in the [chat format](/docs/guides/chat/introduction).
    public var messages: [ChatCompletionRequestMessage]
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    /// 
    /// We generally recommend altering this or `top_p` but not both.
    public var temperature: Double?
    /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    /// 
    /// We generally recommend altering this or `temperature` but not both.
    public var topP: Double?
    /// How many chat completion choices to generate for each input message.
    public var n: Int?
    /// If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message.
    public var isStream: Bool
    /// Up to 4 sequences where the API will stop generating further tokens.
    public var stop: Stop?
    /// The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens).
    public var maxTokens: Int?
    /// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
    /// 
    /// [See more information about frequency and presence penalties.](/docs/api-reference/parameter-details)
    public var presencePenalty: Double?
    /// Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
    /// 
    /// [See more information about frequency and presence penalties.](/docs/api-reference/parameter-details)
    public var frequencyPenalty: Double?
    /// Modify the likelihood of specified tokens appearing in the completion.
    /// 
    /// Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
    public var logitBias: [String: AnyJSON]?
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
    ///
    /// Example: "user-1234"
    public var user: String?

    /// Up to 4 sequences where the API will stop generating further tokens.
    public enum Stop: Codable {
        case string(String)
        case strings([String])

        public init(from decoder: Decoder) throws {
            let container = try decoder.singleValueContainer()
            if let value = try? container.decode(String.self) {
                self = .string(value)
            } else if let value = try? container.decode([String].self) {
                self = .strings(value)
            } else {
                throw DecodingError.dataCorruptedError(
                    in: container,
                    debugDescription: "Data could not be decoded as any of the expected types (String, [String])."
                )
            }
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.singleValueContainer()
            switch self {
            case .string(let value): try container.encode(value)
            case .strings(let value): try container.encode(value)
            }
        }
    }

    public init(model: String, messages: [ChatCompletionRequestMessage], temperature: Double? = nil, topP: Double? = nil, n: Int? = nil, isStream: Bool? = nil, stop: Stop? = nil, maxTokens: Int? = nil, presencePenalty: Double? = nil, frequencyPenalty: Double? = nil, logitBias: [String: AnyJSON]? = nil, user: String? = nil) {
        self.model = model
        self.messages = messages
        self.temperature = temperature
        self.topP = topP
        self.n = n
        self.isStream = isStream ?? false
        self.stop = stop
        self.maxTokens = maxTokens
        self.presencePenalty = presencePenalty
        self.frequencyPenalty = frequencyPenalty
        self.logitBias = logitBias
        self.user = user
    }

    public init(from decoder: Decoder) throws {
        let values = try decoder.container(keyedBy: StringCodingKey.self)
        self.model = try values.decode(String.self, forKey: "model")
        self.messages = try values.decode([ChatCompletionRequestMessage].self, forKey: "messages")
        self.temperature = try values.decodeIfPresent(Double.self, forKey: "temperature")
        self.topP = try values.decodeIfPresent(Double.self, forKey: "top_p")
        self.n = try values.decodeIfPresent(Int.self, forKey: "n")
        self.isStream = try values.decodeIfPresent(Bool.self, forKey: "stream") ?? false
        self.stop = try values.decodeIfPresent(Stop.self, forKey: "stop")
        self.maxTokens = try values.decodeIfPresent(Int.self, forKey: "max_tokens")
        self.presencePenalty = try values.decodeIfPresent(Double.self, forKey: "presence_penalty")
        self.frequencyPenalty = try values.decodeIfPresent(Double.self, forKey: "frequency_penalty")
        self.logitBias = try values.decodeIfPresent([String: AnyJSON].self, forKey: "logit_bias")
        self.user = try values.decodeIfPresent(String.self, forKey: "user")
    }

    public func encode(to encoder: Encoder) throws {
        var values = encoder.container(keyedBy: StringCodingKey.self)
        try values.encode(model, forKey: "model")
        try values.encode(messages, forKey: "messages")
        try values.encodeIfPresent(temperature, forKey: "temperature")
        try values.encodeIfPresent(topP, forKey: "top_p")
        try values.encodeIfPresent(n, forKey: "n")
        try values.encodeIfPresent(isStream, forKey: "stream")
        try values.encodeIfPresent(stop, forKey: "stop")
        try values.encodeIfPresent(maxTokens, forKey: "max_tokens")
        try values.encodeIfPresent(presencePenalty, forKey: "presence_penalty")
        try values.encodeIfPresent(frequencyPenalty, forKey: "frequency_penalty")
        try values.encodeIfPresent(logitBias, forKey: "logit_bias")
        try values.encodeIfPresent(user, forKey: "user")
    }
}

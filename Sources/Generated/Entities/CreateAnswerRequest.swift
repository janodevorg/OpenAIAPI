// Generated by Create API
// https://github.com/CreateAPI/CreateAPI

import Foundation

public struct CreateAnswerRequest: Codable {
    /// ID of the model to use for completion. You can select one of `ada`, `babbage`, `curie`, or `davinci`.
    public var model: String
    /// Question to get answered.
    ///
    /// Example: "What is the capital of Japan?"
    public var question: String
    /// List of (question, answer) pairs that will help steer the model towards the tone and answer format you'd like. We recommend adding 2 to 3 examples.
    ///
    /// Example: "[['What is the capital of Canada?', 'Ottawa'], ['Which province is Ottawa in?', 'Ontario']]"
    public var examples: [[String]]
    /// A text snippet containing the contextual information used to generate the answers for the `examples` you provide.
    ///
    /// Example: "Ottawa, Canada's capital, is located in the east of southern Ontario, near the city of Montr√©al and the U.S. border."
    public var examplesContext: String
    /// List of documents from which the answer for the input `question` should be derived. If this is an empty list, the question will be answered based on the question-answer examples.
    /// 
    /// You should specify either `documents` or a `file`, but not both.
    ///
    /// Example: "['Japan is an island country in East Asia, located in the northwest Pacific Ocean.', 'Tokyo is the capital and most populous prefecture of Japan.']"
    public var documents: [String]?
    /// The ID of an uploaded file that contains documents to search over. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.
    /// 
    /// You should specify either `documents` or a `file`, but not both.
    public var file: String?
    /// ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`.
    public var searchModel: String?
    /// The maximum number of documents to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost.
    public var maxRerank: Int?
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    public var temperature: Double?
    /// Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
    /// 
    /// The maximum value for `logprobs` is 5. If you need more than this, please contact us through our [Help center](https://help.openai.com) and describe your use case.
    /// 
    /// When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs.
    public var logprobs: Int?
    /// The maximum number of tokens allowed for the generated answer
    public var maxTokens: Int?
    /// Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
    public var stop: Stop?
    /// How many answers to generate for each question.
    public var n: Int?
    /// Modify the likelihood of specified tokens appearing in the completion.
    /// 
    /// Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
    /// 
    /// As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
    public var logitBias: [String: AnyJSON]?
    /// A special boolean flag for showing metadata. If set to `true`, each document entry in the returned JSON will contain a "metadata" field.
    /// 
    /// This flag only takes effect when `file` is set.
    public var isReturnMetadata: Bool
    /// If set to `true`, the returned JSON will include a "prompt" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.
    public var isReturnPrompt: Bool
    /// If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support `completion` and `file` objects for expansion.
    public var expand: [AnyJSON]?
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
    ///
    /// Example: "user-1234"
    public var user: String?

    /// Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
    public enum Stop: Codable {
        case string(String)
        case strings([String])

        public init(from decoder: Decoder) throws {
            let container = try decoder.singleValueContainer()
            if let value = try? container.decode(String.self) {
                self = .string(value)
            } else if let value = try? container.decode([String].self) {
                self = .strings(value)
            } else {
                throw DecodingError.dataCorruptedError(
                    in: container,
                    debugDescription: "Data could not be decoded as any of the expected types (String, [String])."
                )
            }
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.singleValueContainer()
            switch self {
            case .string(let value): try container.encode(value)
            case .strings(let value): try container.encode(value)
            }
        }
    }

    public init(model: String, question: String, examples: [[String]], examplesContext: String, documents: [String]? = nil, file: String? = nil, searchModel: String? = nil, maxRerank: Int? = nil, temperature: Double? = nil, logprobs: Int? = nil, maxTokens: Int? = nil, stop: Stop? = nil, n: Int? = nil, logitBias: [String: AnyJSON]? = nil, isReturnMetadata: Bool? = nil, isReturnPrompt: Bool? = nil, expand: [AnyJSON]? = nil, user: String? = nil) {
        self.model = model
        self.question = question
        self.examples = examples
        self.examplesContext = examplesContext
        self.documents = documents
        self.file = file
        self.searchModel = searchModel
        self.maxRerank = maxRerank
        self.temperature = temperature
        self.logprobs = logprobs
        self.maxTokens = maxTokens
        self.stop = stop
        self.n = n
        self.logitBias = logitBias
        self.isReturnMetadata = isReturnMetadata ?? false
        self.isReturnPrompt = isReturnPrompt ?? false
        self.expand = expand
        self.user = user
    }

    public init(from decoder: Decoder) throws {
        let values = try decoder.container(keyedBy: StringCodingKey.self)
        self.model = try values.decode(String.self, forKey: "model")
        self.question = try values.decode(String.self, forKey: "question")
        self.examples = try values.decode([[String]].self, forKey: "examples")
        self.examplesContext = try values.decode(String.self, forKey: "examples_context")
        self.documents = try values.decodeIfPresent([String].self, forKey: "documents")
        self.file = try values.decodeIfPresent(String.self, forKey: "file")
        self.searchModel = try values.decodeIfPresent(String.self, forKey: "search_model")
        self.maxRerank = try values.decodeIfPresent(Int.self, forKey: "max_rerank")
        self.temperature = try values.decodeIfPresent(Double.self, forKey: "temperature")
        self.logprobs = try values.decodeIfPresent(Int.self, forKey: "logprobs")
        self.maxTokens = try values.decodeIfPresent(Int.self, forKey: "max_tokens")
        self.stop = try values.decodeIfPresent(Stop.self, forKey: "stop")
        self.n = try values.decodeIfPresent(Int.self, forKey: "n")
        self.logitBias = try values.decodeIfPresent([String: AnyJSON].self, forKey: "logit_bias")
        self.isReturnMetadata = try values.decodeIfPresent(Bool.self, forKey: "return_metadata") ?? false
        self.isReturnPrompt = try values.decodeIfPresent(Bool.self, forKey: "return_prompt") ?? false
        self.expand = try values.decodeIfPresent([AnyJSON].self, forKey: "expand")
        self.user = try values.decodeIfPresent(String.self, forKey: "user")
    }

    public func encode(to encoder: Encoder) throws {
        var values = encoder.container(keyedBy: StringCodingKey.self)
        try values.encode(model, forKey: "model")
        try values.encode(question, forKey: "question")
        try values.encode(examples, forKey: "examples")
        try values.encode(examplesContext, forKey: "examples_context")
        try values.encodeIfPresent(documents, forKey: "documents")
        try values.encodeIfPresent(file, forKey: "file")
        try values.encodeIfPresent(searchModel, forKey: "search_model")
        try values.encodeIfPresent(maxRerank, forKey: "max_rerank")
        try values.encodeIfPresent(temperature, forKey: "temperature")
        try values.encodeIfPresent(logprobs, forKey: "logprobs")
        try values.encodeIfPresent(maxTokens, forKey: "max_tokens")
        try values.encodeIfPresent(stop, forKey: "stop")
        try values.encodeIfPresent(n, forKey: "n")
        try values.encodeIfPresent(logitBias, forKey: "logit_bias")
        try values.encodeIfPresent(isReturnMetadata, forKey: "return_metadata")
        try values.encodeIfPresent(isReturnPrompt, forKey: "return_prompt")
        try values.encodeIfPresent(expand, forKey: "expand")
        try values.encodeIfPresent(user, forKey: "user")
    }
}

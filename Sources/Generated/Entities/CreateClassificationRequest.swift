// Generated by Create API
// https://github.com/CreateAPI/CreateAPI

import Foundation

public struct CreateClassificationRequest: Codable {
    /// ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
    public var model: String
    /// Query to be classified.
    ///
    /// Example: "The plot is not very attractive."
    public var query: String
    /// A list of examples with labels, in the following format:
    /// 
    /// `[["The movie is so interesting.", "Positive"], ["It is quite boring.", "Negative"], ...]`
    /// 
    /// All the label strings will be normalized to be capitalized.
    /// 
    /// You should specify either `examples` or `file`, but not both.
    ///
    /// Example: "[['Do not see this film.', 'Negative'], ['Smart, provocative and blisteringly funny.', 'Positive']]"
    public var examples: [[String]]?
    /// The ID of the uploaded file that contains training examples. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.
    /// 
    /// You should specify either `examples` or `file`, but not both.
    public var file: String?
    /// The set of categories being classified. If not specified, candidate labels will be automatically collected from the examples you provide. All the label strings will be normalized to be capitalized.
    ///
    /// Example: ["Positive", "Negative"]
    public var labels: [String]?
    /// ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`.
    public var searchModel: String?
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    public var temperature: Double?
    /// Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
    /// 
    /// The maximum value for `logprobs` is 5. If you need more than this, please contact us through our [Help center](https://help.openai.com) and describe your use case.
    /// 
    /// When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs.
    public var logprobs: Int?
    /// The maximum number of examples to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost.
    public var maxExamples: Int?
    /// Modify the likelihood of specified tokens appearing in the completion.
    /// 
    /// Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
    /// 
    /// As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
    public var logitBias: [String: AnyJSON]?
    /// If set to `true`, the returned JSON will include a "prompt" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.
    public var isReturnPrompt: Bool
    /// A special boolean flag for showing metadata. If set to `true`, each document entry in the returned JSON will contain a "metadata" field.
    /// 
    /// This flag only takes effect when `file` is set.
    public var isReturnMetadata: Bool
    /// If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support `completion` and `file` objects for expansion.
    public var expand: [AnyJSON]?
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
    ///
    /// Example: "user-1234"
    public var user: String?

    public init(model: String, query: String, examples: [[String]]? = nil, file: String? = nil, labels: [String]? = nil, searchModel: String? = nil, temperature: Double? = nil, logprobs: Int? = nil, maxExamples: Int? = nil, logitBias: [String: AnyJSON]? = nil, isReturnPrompt: Bool? = nil, isReturnMetadata: Bool? = nil, expand: [AnyJSON]? = nil, user: String? = nil) {
        self.model = model
        self.query = query
        self.examples = examples
        self.file = file
        self.labels = labels
        self.searchModel = searchModel
        self.temperature = temperature
        self.logprobs = logprobs
        self.maxExamples = maxExamples
        self.logitBias = logitBias
        self.isReturnPrompt = isReturnPrompt ?? false
        self.isReturnMetadata = isReturnMetadata ?? false
        self.expand = expand
        self.user = user
    }

    public init(from decoder: Decoder) throws {
        let values = try decoder.container(keyedBy: StringCodingKey.self)
        self.model = try values.decode(String.self, forKey: "model")
        self.query = try values.decode(String.self, forKey: "query")
        self.examples = try values.decodeIfPresent([[String]].self, forKey: "examples")
        self.file = try values.decodeIfPresent(String.self, forKey: "file")
        self.labels = try values.decodeIfPresent([String].self, forKey: "labels")
        self.searchModel = try values.decodeIfPresent(String.self, forKey: "search_model")
        self.temperature = try values.decodeIfPresent(Double.self, forKey: "temperature")
        self.logprobs = try values.decodeIfPresent(Int.self, forKey: "logprobs")
        self.maxExamples = try values.decodeIfPresent(Int.self, forKey: "max_examples")
        self.logitBias = try values.decodeIfPresent([String: AnyJSON].self, forKey: "logit_bias")
        self.isReturnPrompt = try values.decodeIfPresent(Bool.self, forKey: "return_prompt") ?? false
        self.isReturnMetadata = try values.decodeIfPresent(Bool.self, forKey: "return_metadata") ?? false
        self.expand = try values.decodeIfPresent([AnyJSON].self, forKey: "expand")
        self.user = try values.decodeIfPresent(String.self, forKey: "user")
    }

    public func encode(to encoder: Encoder) throws {
        var values = encoder.container(keyedBy: StringCodingKey.self)
        try values.encode(model, forKey: "model")
        try values.encode(query, forKey: "query")
        try values.encodeIfPresent(examples, forKey: "examples")
        try values.encodeIfPresent(file, forKey: "file")
        try values.encodeIfPresent(labels, forKey: "labels")
        try values.encodeIfPresent(searchModel, forKey: "search_model")
        try values.encodeIfPresent(temperature, forKey: "temperature")
        try values.encodeIfPresent(logprobs, forKey: "logprobs")
        try values.encodeIfPresent(maxExamples, forKey: "max_examples")
        try values.encodeIfPresent(logitBias, forKey: "logit_bias")
        try values.encodeIfPresent(isReturnPrompt, forKey: "return_prompt")
        try values.encodeIfPresent(isReturnMetadata, forKey: "return_metadata")
        try values.encodeIfPresent(expand, forKey: "expand")
        try values.encodeIfPresent(user, forKey: "user")
    }
}
